{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import display\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# setting working directory\n",
    "os.chdir('/Users/sherry/PhD-research/paper-recommendation/feature_vector_datasets/Kazunari-Sugiyam/20131106-SchPaperRecData/ScholarlyPaperRecData')\n",
    "\n",
    "# functions to compute cosine similarity score\n",
    "def cosine(fv1_file:str, fv2_file:str):\n",
    "    \"\"\"\n",
    "    fv1_file: featrue vector file path, e.g fv1_path = 'rlv/R49/CHI07-p1253-lampe_fv.txt'\n",
    "    \"\"\"\n",
    "    fv1 = pd.read_csv(fv1_file, names=['token', 'tf/tfidf'], header=None, delimiter=' ')\n",
    "    fv2 = pd.read_csv(fv2_file, names=['token', 'tf/tfidf'], header=None, delimiter=' ')\n",
    "\n",
    "    #avoidind empty input file, there are some feature vector files that are empty.\n",
    "    if len(fv1) == 0 or len(fv2) == 0:\n",
    "        cos = None\n",
    "        return cos\n",
    "\n",
    "    # Merge the two DataFrames based on the 'token' column\n",
    "    merged_df = pd.merge(fv1, fv2, on='token', how='outer')\n",
    "\n",
    "    # replace missing value NaN with 0\n",
    "    merged_df = merged_df.fillna(0)\n",
    "\n",
    "    # Get the 'tf/tfidf' value columns as arrays\n",
    "    values1 = merged_df['tf/tfidf_x'].values.reshape(1, -1)\n",
    "    values2 = merged_df['tf/tfidf_y'].values.reshape(1, -1)\n",
    "\n",
    "    # Compute the cosine similarity\n",
    "    cosine_sim = cosine_similarity(values1, values2)\n",
    "\n",
    "    return cosine_sim[0,0]\n",
    "\n",
    "def cos_weight_fv(fv1_file:str, fv2_file:str):\n",
    "    \"\"\"\n",
    "    fv1_file: featrue vector file path of a user's publication, \n",
    "            e.g fv1_path = 'rlv/R49/CHI07-p1253-lampe_fv.txt'\n",
    "    fv2_file: featrue vector file path of a citation paper or a reference paper \n",
    "            of the publication\n",
    "    return fv2: featrue vector dataframe with two columns ['token', 'tf/tfidf']\n",
    "    \n",
    "    \"\"\"\n",
    "    cos_weight = cosine(fv1_file, fv2_file)\n",
    "    fv2 = pd.read_csv(fv2_file, names=['token', 'tf/tfidf'], header=None, delimiter=' ')\n",
    "    fv2['tf/tfidf'] = cos_weight * fv2['tf/tfidf']\n",
    "    return fv2\n",
    "\n",
    "\n",
    "def cos_fv_input(fv1:pd.DataFrame, fv2:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    fv1: featrue vector dataframe with two columns ['token', 'tf/tfidf']\n",
    "    \"\"\"\n",
    "    # avoidind empty input file, there are some feature vector files that are empty.\n",
    "    # if len(fv1) == 0 or len(fv2) == 0:\n",
    "    #     cos = None\n",
    "    #     return cos\n",
    "    \n",
    "    # Merge the two DataFrames based on the 'token' column\n",
    "    merged_df = pd.merge(fv1, fv2, on='token', how='outer')\n",
    "\n",
    "    # replace missing value NaN with 0\n",
    "    merged_df = merged_df.fillna(0)\n",
    "\n",
    "    # Get the 'tf/tfidf' value columns as arrays\n",
    "    values1 = merged_df['tf/tfidf_x'].values.reshape(1, -1)\n",
    "    values2 = merged_df['tf/tfidf_y'].values.reshape(1, -1)\n",
    "\n",
    "    # Compute the cosine similarity, cosine_sim:np.array\n",
    "    cosine_sim = cosine_similarity(values1, values2)\n",
    "\n",
    "    return cosine_sim[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting R1\n",
      "n: 4, std: 0.291\n",
      "finished R1\n",
      "Starting R2\n",
      "n: 12, std: 0.146\n",
      "finished R2\n",
      "Starting R3\n",
      "n: 7, std: 0.135\n",
      "finished R3\n",
      "Starting R4\n",
      "n: 5, std: 0.108\n",
      "finished R4\n",
      "Starting R5\n",
      "n: 2, std: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherry/Library/Python/3.9/lib/python/site-packages/numpy/lib/scimath.py:386: RuntimeWarning: divide by zero encountered in log\n",
      "  return nx.log(x)/nx.log(n)\n",
      "/var/folders/w6/6g3zflgd0kd42nr34tk02bx00000gn/T/ipykernel_18249/4237106901.py:23: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  norm_weight = weight/sum(weights_ls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished R5\n",
      "Starting R6\n",
      "n: 7, std: 0.114\n",
      "finished R6\n",
      "Starting R7\n",
      "n: 16, std: 0.088\n",
      "finished R7\n",
      "Starting R8\n",
      "n: 7, std: 0.226\n",
      "finished R8\n",
      "Starting R9\n",
      "n: 13, std: 0.115\n",
      "finished R9\n",
      "Starting R10\n",
      "n: 5, std: 0.073\n",
      "finished R10\n",
      "Starting R11\n",
      "n: 12, std: 0.075\n",
      "finished R11\n",
      "Starting R12\n",
      "n: 14, std: 0.108\n",
      "finished R12\n",
      "Starting R13\n",
      "n: 9, std: 0.116\n",
      "finished R13\n",
      "Starting R14\n",
      "n: 14, std: 0.271\n",
      "finished R14\n",
      "Starting R15\n",
      "n: 5, std: 0.07\n",
      "finished R15\n",
      "Starting R16\n",
      "n: 18, std: 0.104\n",
      "finished R16\n",
      "Starting R17\n",
      "n: 12, std: 0.125\n",
      "finished R17\n",
      "Starting R18\n",
      "n: 4, std: 0.236\n",
      "finished R18\n",
      "Starting R19\n",
      "n: 4, std: 0.085\n",
      "finished R19\n",
      "Starting R20\n",
      "n: 12, std: 0.096\n",
      "finished R20\n",
      "Starting R21\n",
      "n: 8, std: 0.076\n",
      "finished R21\n",
      "Starting R22\n",
      "n: 22, std: 0.096\n",
      "finished R22\n",
      "Starting R23\n",
      "n: 24, std: 0.113\n",
      "finished R23\n",
      "Starting R24\n",
      "n: 18, std: 0.122\n",
      "finished R24\n",
      "Starting R25\n",
      "n: 19, std: 0.095\n",
      "finished R25\n",
      "Starting R26\n",
      "n: 3, std: 0.049\n",
      "finished R26\n",
      "Starting R27\n",
      "n: 24, std: 0.144\n",
      "finished R27\n",
      "Starting R28\n",
      "n: 17, std: 0.088\n",
      "finished R28\n",
      "Starting R29\n",
      "n: 3, std: 0.094\n",
      "finished R29\n",
      "Starting R30\n",
      "n: 7, std: 0.09\n",
      "finished R30\n",
      "Starting R31\n",
      "n: 24, std: 0.109\n",
      "finished R31\n",
      "Starting R32\n",
      "n: 3, std: 0.031\n",
      "finished R32\n",
      "Starting R33\n",
      "n: 9, std: 0.088\n",
      "finished R33\n",
      "Starting R34\n",
      "n: 3, std: 0.103\n",
      "finished R34\n",
      "Starting R35\n",
      "n: 22, std: 0.095\n",
      "finished R35\n",
      "Starting R36\n",
      "n: 13, std: 0.121\n",
      "finished R36\n",
      "Starting R37\n",
      "n: 13, std: 0.113\n",
      "finished R37\n",
      "Starting R38\n",
      "n: 22, std: 0.113\n",
      "finished R38\n",
      "Starting R39\n",
      "n: 14, std: 0.083\n",
      "finished R39\n",
      "Starting R40\n",
      "n: 11, std: 0.103\n",
      "finished R40\n",
      "Starting R41\n",
      "n: 31, std: 0.109\n",
      "finished R41\n",
      "Starting R42\n",
      "n: 2, std: 0.181\n",
      "finished R42\n",
      "Starting R43\n",
      "n: 6, std: 0.137\n",
      "finished R43\n",
      "Starting R44\n",
      "n: 6, std: 0.103\n",
      "finished R44\n",
      "Starting R45\n",
      "n: 3, std: 0.037\n",
      "finished R45\n",
      "Starting R46\n",
      "n: 8, std: 0.066\n",
      "finished R46\n",
      "Starting R47\n",
      "n: 4, std: 0.054\n",
      "finished R47\n",
      "Starting R48\n",
      "n: 3, std: 0.189\n",
      "finished R48\n",
      "Starting R49\n",
      "n: 5, std: 0.09\n",
      "finished R49\n",
      "Starting R50\n",
      "n: 4, std: 0.091\n",
      "finished R50\n"
     ]
    }
   ],
   "source": [
    "# ************ using all publications to construct user profile\n",
    "# for researcher R who have n publications\n",
    "# *** user_fv = FVp1 + FVp2 +...FVpn\n",
    "\n",
    "user_statistics_df = pd.read_csv('user_profiles_statistics.csv')\n",
    "num_pubs_ls = user_statistics_df.iloc[:,1].tolist()\n",
    "\n",
    "user_stats = pd.read_csv('std.csv', header=0)\n",
    "user_std = user_stats['std']\n",
    "\n",
    "################################################## weighting function #####################\n",
    "# weighted parameter\n",
    "def fstd_weight(n, std, a=0.1, b=1):\n",
    "    weights_ls = []\n",
    "    for i in range(1,n+1):\n",
    "        # (1-i/n) ranges from (n-i)/n to 1/n\n",
    "        # emath.logn(n, x),Take log base n of x.\n",
    "        # x = std + a # 0<x<1, base = (i+b) # base > 1\n",
    "        weight = -1 * np.emath.logn(i+b, std*std)\n",
    "        weights_ls.append(weight)\n",
    "    norm_weights_ls = []\n",
    "    for weight in weights_ls:\n",
    "        norm_weight = weight/sum(weights_ls)\n",
    "        norm_weights_ls.append(norm_weight)\n",
    "    # print(sum(norm_weights_ls))\n",
    "    return norm_weights_ls\n",
    "################################################## weighting function #####################\n",
    "\n",
    "os.chdir('/Users/sherry/PhD-research/paper-recommendation/feature_vector_datasets/Kazunari-Sugiyam/20131106-SchPaperRecData/ScholarlyPaperRecData/')\n",
    "\n",
    "############################# change results path #############################\n",
    "cos_results_path = \"result/fstd_weights\"\n",
    "############################# change results path #############################\n",
    "\n",
    "for r in range(1,51,1):\n",
    "    print(f'Starting R{r}')\n",
    "    user_fv = pd.DataFrame(columns=['token','tf/tfidf'])\n",
    "    fvs = []\n",
    "    # get number of publications for the researcher\n",
    "    n = num_pubs_ls[r-1]\n",
    "    std = user_std[r-1]\n",
    "    print(f\"n: {n}, std: {std}\")\n",
    "    a = 0.1\n",
    "    b = 10\n",
    "    norm_weights_ls = fstd_weight(n, std, a, b)\n",
    "    for i in range(1,n,1):\n",
    "        fv_path = 'Researchers/R{}/FeatureVectors/R{}-{}/R{}-{}_fv.txt'.format(r,r,i,r,i)\n",
    "        fv = pd.read_csv(fv_path, names=['token', 'tf/tfidf'], header=None, delimiter=' ')\n",
    "        # weighted feature vector \n",
    "        fv['tf/tfidf'] = fv['tf/tfidf'] * norm_weights_ls[i-1]\n",
    "        fvs.append(fv)\n",
    "    # concatenate all publications fv:pd.DataFrame to construct researcher's profile \n",
    "    pub_fv = pd.DataFrame(columns=['token','tf/tfidf'])\n",
    "    for fv in fvs:\n",
    "        pub_fv = pd.concat([pub_fv,fv])\n",
    "    user_fv = pub_fv.groupby('token').sum().reset_index()\n",
    "\n",
    "    # iterate all files in a directory and its subdirectories to get the paperID and paperFV\n",
    "    # and then compute the cosine score between (user_fv, fv_candidate)\n",
    "    root = 'RecCandidatePapersFV'\n",
    "    paperID_ls = []\n",
    "    cos_ls = []\n",
    "    result_df = pd.DataFrame(columns=['paperID', 'cosine_score'])\n",
    "    for path, subdir, files in os.walk(root):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(path, name)\n",
    "            # display(file_path)\n",
    "            if file_path.endswith('.txt'):\n",
    "                fv_candidate = pd.read_csv(file_path, names=['token', 'tf/tfidf'], header=None, delimiter=' ')\n",
    "                cosine_score = cos_fv_input(user_fv, fv_candidate)\n",
    "                paperID = name.replace('_fv.txt' , '')\n",
    "                paperID_ls.append(paperID)\n",
    "                cos_ls.append(cosine_score)\n",
    "            else: # ignore other system files such as .DSstore in MacOS\n",
    "                pass\n",
    "    result_df['paperID'] = paperID_ls\n",
    "    result_df['cosine_score'] = cos_ls\n",
    "    sorted_df = result_df.sort_values('cosine_score', ascending=False)\n",
    "    sorted_df.to_csv(f'{cos_results_path}/R{r}_cosine.csv')  \n",
    "    print('finished R{}'.format(r)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "'''for each researcher:\n",
    "1. read all interested papers from txt file into a list as ground truth\n",
    "2. read recommending result from csv file into a dataframe\n",
    "3. check each recommending paper to see if it hits the ground truth\n",
    "'''\n",
    "\n",
    "class Metrics():\n",
    "    \"\"\" \n",
    "        :param rank_ls: list, prediction [1,0,1,0,1,1,1], 1 denotes relevant item and 0 denotes irrelevant item\n",
    "        :k: int\n",
    "    \"\"\"    \n",
    "    def __init__(self, rank_ls:list, k:int) -> None:\n",
    "        self.rank_ls = rank_ls\n",
    "        self.k = k\n",
    "    \n",
    "    def get_precision(self):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for i in self.rank_ls[0:self.k]:\n",
    "            if i == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        p = tp/self.k\n",
    "        return round(p, 3)\n",
    "\n",
    "    def get_recall(self, total_positive:int):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for i in self.rank_ls[0:self.k]:\n",
    "            if i == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        recall = tp/self.k\n",
    "        return round(recall, 3)\n",
    "\n",
    "    def get_fscore(self, total_positive:int):\n",
    "        p = self.get_precision()\n",
    "        r = self.get_recall(total_positive)\n",
    "        if (p+r) != 0:\n",
    "            f1 = 2*p*r/(p+r)\n",
    "        else:\n",
    "            return 0\n",
    "        return round(f1, 3)\n",
    "\n",
    "    def get_reciprocal_rank(self):\n",
    "        rr = 0.0\n",
    "        for index,item in enumerate(self.rank_ls[0:self.k]):\n",
    "            if item == 1:\n",
    "                rr = 1.0 / (index + 1.0)\n",
    "                break\n",
    "        return round(rr, 3)\n",
    "\n",
    "    def get_average_p(self):\n",
    "        p_ls = []\n",
    "        for index,item in enumerate(self.rank_ls[0:self.k]):\n",
    "            if item == 1:\n",
    "                p_ls.append(1.0 / (index + 1))\n",
    "        if len(p_ls) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return round(np.mean(p_ls), 3)  \n",
    "        \n",
    "    \n",
    "    def get_dcg(self):\n",
    "        \"\"\"\n",
    "        :param rank_ls: list, such as  [1,0,1,0,1,1,1], 1 denotes relevant item and 0 denotes irrelevant item\n",
    "        :return dcg: the dcg value of the input rank list\n",
    "        \"\"\"\n",
    "        n = self.k\n",
    "        dcg = 0\n",
    "        for i in range(n):\n",
    "            pos = i + 1\n",
    "            # here gains is 1 or 0\n",
    "            gains = self.rank_ls[i]\n",
    "            discounts = np.log2(pos + 1)\n",
    "            if gains == 0:\n",
    "                cg = 0\n",
    "            else:\n",
    "                cg = (gains / discounts)\n",
    "            dcg += cg\n",
    "        return dcg\n",
    "\n",
    "    def get_idcg(self):\n",
    "        \"\"\"\n",
    "        :param rank_ls: list, such as  [1,0,1,0,1,1,1], 1 denotes relevant item and 0 denotes irrelevant item\n",
    "        :return idcg: the ideal dcg value of the input rank list\n",
    "        \"\"\"\n",
    "        ideal_rank_ls = sorted(self.rank_ls, reverse=True)\n",
    "        n = self.k\n",
    "        idcg = 0\n",
    "        for i in range(n):\n",
    "            pos = i + 1\n",
    "            # here gains is 1 or 0\n",
    "            gains = ideal_rank_ls[i]\n",
    "            discounts = np.log2(pos + 1)\n",
    "            if gains == 0:\n",
    "                cg = 0\n",
    "            else:\n",
    "                cg = (gains / discounts)\n",
    "            idcg += cg\n",
    "        return idcg\n",
    "\n",
    "    def get_ndcg(self):\n",
    "        \"\"\"\n",
    "        :param rank_list: list, such as  [1,0,1,0,1,1,1], 1 denotes relevant item and 0 denotes irrelevant item\n",
    "        :return ndcg: the ideal dcg value of the input rank list\n",
    "        \"\"\"\n",
    "        if self.get_dcg() == 0:\n",
    "            ndcg = 0\n",
    "        else:\n",
    "            ndcg = self.get_dcg()/self.get_idcg()\n",
    "        return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result/fstd_weights\n",
      "\n",
      "NDCG@10: 0.29892374972112845\n",
      "MRR: 0.33887999999999996\n",
      "P@10: 0.096\n"
     ]
    }
   ],
   "source": [
    "for r in range(1,51,1):\n",
    "    gt_df = pd.read_csv('ground_truth/rlv_list/R{}-rlv.txt'.format(r), header=None)\n",
    "    gt_df.columns = ['papeID']\n",
    "    gt_set = set(gt_df.papeID)\n",
    "    \n",
    "    #### recommendation result in csv with two column ['paperID', ['cosine_score']]\n",
    "    path = f'{cos_results_path}/R{r}_cosine.csv'\n",
    "    recommending_df = pd.read_csv(path, index_col=0, nrows=30)\n",
    "    hit_ls = []\n",
    "    for id in recommending_df.paperID:\n",
    "        if id in gt_set:\n",
    "            hit_ls.append(1)\n",
    "        else:\n",
    "            hit_ls.append(0)\n",
    "    recommending_df['hit'] = hit_ls\n",
    "    recommending_df.to_csv(f'{cos_results_path}/R{r}_hit.csv')\n",
    "\n",
    "# calculate the metrics\n",
    "total_positives = pd.read_csv('user_profiles_statistics.csv')['numbers of interest paper']\n",
    "#for each researcher\n",
    "p_ls, r_ls, f1_ls, map_ls, mrr_ls, ndcg_ls= ([],[],[],[],[],[])\n",
    "r = 1\n",
    "n = 50\n",
    "for r in range(1,51,1):\n",
    "    data = pd.read_csv(f'{cos_results_path}/R{r}_hit.csv')\n",
    "    rank_ls = data.hit\n",
    "    evaluation = Metrics(rank_ls=rank_ls, k=10)\n",
    "    precision = evaluation.get_precision()\n",
    "    p_ls.append(precision)\n",
    "\n",
    "    recall = evaluation.get_recall(total_positive=total_positives[r-1])\n",
    "    r_ls.append(recall)\n",
    "\n",
    "    f1 = evaluation.get_fscore(total_positive=total_positives[r-1])\n",
    "    f1_ls.append(f1)\n",
    "\n",
    "    rr = evaluation.get_reciprocal_rank()\n",
    "    mrr_ls.append(rr)\n",
    "    \n",
    "    ap = evaluation.get_average_p()\n",
    "    map_ls.append(ap)\n",
    "\n",
    "    ap = evaluation.get_ndcg()\n",
    "    ndcg_ls.append(ap)\n",
    "\n",
    "avg_p = np.mean(p_ls)\n",
    "avg_r = np.mean(r_ls)\n",
    "avg_f1 = np.mean(f1_ls)\n",
    "mrr = np.mean(mrr_ls)\n",
    "map = np.mean(map_ls)\n",
    "avg_ndcg = np.mean(ndcg_ls)\n",
    "\n",
    "print(f'{cos_results_path}\\n')\n",
    "print('NDCG@10: {}'.format(avg_ndcg))\n",
    "print('MRR: {}'.format(mrr))\n",
    "print('P@10: {}'.format(avg_p))\n",
    "# print('Recall: {}'.format(avg_r))\n",
    "# print('F1: {}'.format(avg_f1))\n",
    "# print('MAP: {}'.format(map))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
